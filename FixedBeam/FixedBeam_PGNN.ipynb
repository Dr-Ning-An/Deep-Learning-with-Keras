{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Download Data"
      ],
      "metadata": {
        "id": "GkdUdOCehMWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# read data to pandas frame\n",
        "url = 'https://raw.githubusercontent.com/Dr-Ning-An/Deep-Learning-with-Keras/main/FixedBeam/FixedBeamData.csv'\n",
        "data = pd.read_csv(url)\n",
        "data.shape\n",
        "# print(data.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj98lRCPhRHo",
        "outputId": "cfd42873-0229-4521-9d01-7855f20dfe8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000; # data size"
      ],
      "metadata": {
        "id": "ANrRDT-_hd1l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = data.iloc[:, 0:2][0:n] # read the first two columns n size data as inputs\n",
        "# Normalize the inputs\n",
        "inputs_norm = (inputs - inputs.mean()) / inputs.std()\n",
        "n_inputs_norm = inputs_norm.shape[1]\n",
        "print(inputs_norm.head(5))\n",
        "outputs = data.iloc[:, 2:4][0:n] # read the last two columns n size data as inputs\n",
        "# Normalize the outputs\n",
        "outputs_norm = (outputs - outputs.mean()) / outputs.std()\n",
        "n_outputs_norm = outputs_norm.shape[1]\n",
        "print(outputs_norm.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Q-tSskhYAN",
        "outputId": "8fa0f2f6-c679-4319-9533-cf1c2be0f164"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Coordinate x [m]  Distributed load q [kN/m]\n",
            "0         -1.454237                  -1.547295\n",
            "1          0.909583                   1.384380\n",
            "2          1.599804                   1.446492\n",
            "3          1.418131                  -0.169104\n",
            "4         -1.290455                   0.634898\n",
            "   Displacement u [m]  Curvature kappa [m-1]\n",
            "0            1.225377              -0.647131\n",
            "1           -0.503402               0.244706\n",
            "2            1.289010              -2.477319\n",
            "3            1.107871              -1.074265\n",
            "4            0.744695              -0.835861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Randomly split the data into a training and test sets by holding 30% of the data for testing.\n",
        "inputs_norm_train, inputs_norm_test, outputs_norm_train, outputs_norm_test = \\\n",
        "    train_test_split(inputs_norm, outputs_norm, test_size = 0.3, random_state=0)"
      ],
      "metadata": {
        "id": "nVD457b0ibiX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# define regression model using Functional API\n",
        "def build_model():\n",
        "    # create model\n",
        "    inputs = tf.keras.Input(shape=(n_inputs_norm,), dtype=tf.float64)\n",
        "    dense1 = Dense(20, activation='tanh')(inputs)\n",
        "    dense2 = Dense(20, activation='tanh')(dense1)\n",
        "    dense3 = Dense(20, activation='tanh')(dense2)\n",
        "    outputs = Dense(n_outputs_norm)(dense3)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Kh1mfSoViiq5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPWtKqL1jSnu",
        "outputId": "f9ec6a2f-c413-436e-f91d-352d17aece52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                60        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 942\n",
            "Trainable params: 942\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "ZG0MPWE2jc68"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 60\n",
        "EPOCHS = 1000"
      ],
      "metadata": {
        "id": "srQHi5jCjgs8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs_norm_train, outputs_norm_train))\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "hkWOZErbjnc0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain rule\n",
        "\n",
        "$\\frac{d^2u_{norm}}{dx_{norm}^2}$ could be obtained by calculating the gradient of neural network output with respect to input, we then solve $\\frac{d^2u}{dx^2}$ by using the chain rule.\n",
        "\n",
        "$x_{norm} = (x - \\bar{x})/\\sigma_{x}$ \n",
        "\n",
        "$u_{norm} = (u - \\bar{u})/\\sigma_{u}$\n",
        "\n",
        "where $x_{norm}$ and $u_{norm}$ denote the normalized data, $x$ and $u$ represent the naive data, $\\bar{x}$ and $\\bar{u}$ denote the mean of the data, and $\\sigma_{x}$ and $\\sigma_{u}$ denote the standard deviation of the data.\n",
        "\n",
        "$\\frac{d^2u}{dx^2} = \\frac{d^2u}{du_{norm}^2} (\\frac{du_{norm}}{dx})^2 + \\frac{du}{du_{norm}} \\frac{d^2u_{norm}}{dx^2} $\n",
        "\n",
        "$ \\quad \\quad = \\frac{d^2u}{du_{norm}^2} (\\frac{du_{norm}}{dx_{norm}} \\frac{dx_{norm}}{dx})^2 + \\frac{du}{du_{norm}} \\cdot [\\frac{d^2u_{norm}}{dx_{norm}^2} (\\frac{dx_{norm}}{dx})^2 + \\frac{du_{norm}}{dx_{norm}} \\frac{d^2x_{norm}}{dx^2}]$\n",
        "\n",
        "$\\quad \\quad = 0 + \\frac{du}{du_{norm}} \\cdot [\\frac{d^2u_{norm}}{dx_{norm}^2} (\\frac{dx_{norm}}{dx})^2 + 0 ]$\n",
        "\n",
        "$\\quad \\quad = \\frac{du}{du_{norm}} \\cdot \\frac{d^2u_{norm}}{dx_{norm}^2} \\cdot (\\frac{dx_{norm}}{dx})^2 $\n",
        "\n",
        "where $\\frac{du}{du_{norm}} = \\sigma_{u}$ is the standard deviation of $u$ data and $\\frac{dx_{norm}}{dx} = \\frac{1}{\\sigma_{x}}$ and $\\sigma_{x}$ is the standard deviation of $x$ data."
      ],
      "metadata": {
        "id": "G-A0VgQjLee4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PGNN(x_norm, q_norm):\n",
        "    x_norm = tf.Variable(x_norm)\n",
        "    q_norm = tf.Variable(q_norm)\n",
        "    with tf.GradientTape() as g:\n",
        "      g.watch(x_norm)\n",
        "      with tf.GradientTape() as gg:\n",
        "        gg.watch(x_norm)\n",
        "        outputs_norm_pred = tf.cast(model(tf.stack([x_norm,q_norm], axis=1)), tf.float64)\n",
        "        u_norm = outputs_norm_pred[:,0]\n",
        "      du_norm_dx_norm = gg.gradient(u_norm, x_norm) \n",
        "    d2u_norm_dx_norm2 = g.gradient(du_norm_dx_norm, x_norm) \n",
        "\n",
        "    # Chain rule\n",
        "    du_du_norm = outputs.std()[0]\n",
        "    dx_norm_dx = 1/inputs.std()[0]\n",
        "    d2u_dx2 =  du_du_norm *  d2u_norm_dx_norm2 * dx_norm_dx**2\n",
        "\n",
        "    kappa_norm = outputs_norm_pred[:,1]\n",
        "    kappa = kappa_norm * outputs.std()[1] + outputs.mean()[1]\n",
        "    \n",
        "    residual = d2u_dx2 - kappa\n",
        "\n",
        "    return residual"
      ],
      "metadata": {
        "id": "O--YDO01kGMx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(inputs, outputs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        outputs_pred = tf.cast(model(inputs), tf.float64)\n",
        "        residual = PGNN(inputs[:,0],inputs[:,1])\n",
        "        loss1 = tf.losses.MeanSquaredError()(outputs, outputs_pred) \n",
        "        loss2 = tf.reduce_mean(tf.square(residual))\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return loss\n",
        "\n",
        "loss_hist = []\n",
        "for epoch in range(EPOCHS):\n",
        "    ep_loss = []\n",
        "    for step, (inputs_norm_train_batch, outputs_norm_train_batch) in enumerate(dataset):\n",
        "        loss_i = train_step(inputs_norm_train_batch, outputs_norm_train_batch)\n",
        "        ep_loss.append(loss_i)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f\"Epoch {epoch} Loss: {tf.reduce_mean(ep_loss)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU-Xz19LkN0T",
        "outputId": "65cb629a-0ce5-4a22-9bb4-8dbdf5f209f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss: 0.9690413296841491\n",
            "Epoch 1 Loss: 0.9295972120342362\n",
            "Epoch 2 Loss: 0.899739778169136\n",
            "Epoch 3 Loss: 0.8634452583179518\n",
            "Epoch 4 Loss: 0.8178279881112281\n",
            "Epoch 5 Loss: 0.761859613233819\n",
            "Epoch 6 Loss: 0.6964578275430595\n",
            "Epoch 7 Loss: 0.6233314729081549\n",
            "Epoch 8 Loss: 0.5443535767054128\n",
            "Epoch 9 Loss: 0.46213305124303683\n",
            "Epoch 10 Loss: 0.38058792395949137\n",
            "Epoch 11 Loss: 0.30455973108982387\n",
            "Epoch 12 Loss: 0.2384241982442127\n",
            "Epoch 13 Loss: 0.18503482274579885\n",
            "Epoch 14 Loss: 0.14506828256573495\n",
            "Epoch 15 Loss: 0.11690900818913304\n",
            "Epoch 16 Loss: 0.09746163275953353\n",
            "Epoch 17 Loss: 0.08354045061917008\n",
            "Epoch 18 Loss: 0.07283682647181193\n",
            "Epoch 19 Loss: 0.06400296048765486\n",
            "Epoch 20 Loss: 0.056390302481702015\n",
            "Epoch 21 Loss: 0.049769637870584554\n",
            "Epoch 22 Loss: 0.04409490052876939\n",
            "Epoch 23 Loss: 0.03934907806433267\n",
            "Epoch 24 Loss: 0.0354734157477293\n",
            "Epoch 25 Loss: 0.0323561761910171\n",
            "Epoch 26 Loss: 0.02985561406685701\n",
            "Epoch 27 Loss: 0.02783104303719543\n",
            "Epoch 28 Loss: 0.026164187882737177\n",
            "Epoch 29 Loss: 0.024765517227163202\n",
            "Epoch 30 Loss: 0.02357067503044738\n",
            "Epoch 31 Loss: 0.02253389480823227\n",
            "Epoch 32 Loss: 0.021622181226065212\n",
            "Epoch 33 Loss: 0.020811059703964685\n",
            "Epoch 34 Loss: 0.02008190984942013\n",
            "Epoch 35 Loss: 0.019420255317295756\n",
            "Epoch 36 Loss: 0.018814684928368203\n",
            "Epoch 37 Loss: 0.018256058560075703\n",
            "Epoch 38 Loss: 0.017736964569810994\n",
            "Epoch 39 Loss: 0.017251345424152107\n",
            "Epoch 40 Loss: 0.01679418117200146\n",
            "Epoch 41 Loss: 0.016361286064387737\n",
            "Epoch 42 Loss: 0.015949125126239794\n",
            "Epoch 43 Loss: 0.015554691827943596\n",
            "Epoch 44 Loss: 0.015175407564790716\n",
            "Epoch 45 Loss: 0.014809031985565413\n",
            "Epoch 46 Loss: 0.014453626127873072\n",
            "Epoch 47 Loss: 0.014107497801446623\n",
            "Epoch 48 Loss: 0.013769178890286863\n",
            "Epoch 49 Loss: 0.01343739808088905\n",
            "Epoch 50 Loss: 0.013111082992671748\n",
            "Epoch 51 Loss: 0.012789341249026124\n",
            "Epoch 52 Loss: 0.012471442531872705\n",
            "Epoch 53 Loss: 0.012156813260178118\n",
            "Epoch 54 Loss: 0.011845037739664594\n",
            "Epoch 55 Loss: 0.011535820116810628\n",
            "Epoch 56 Loss: 0.011228986844467525\n",
            "Epoch 57 Loss: 0.01092445450291655\n",
            "Epoch 58 Loss: 0.0106222431322996\n",
            "Epoch 59 Loss: 0.010322434266318655\n",
            "Epoch 60 Loss: 0.010025186601019495\n",
            "Epoch 61 Loss: 0.009730693775712063\n",
            "Epoch 62 Loss: 0.009439202069937197\n",
            "Epoch 63 Loss: 0.009151001730141474\n",
            "Epoch 64 Loss: 0.008866404990628183\n",
            "Epoch 65 Loss: 0.008585759938917551\n",
            "Epoch 66 Loss: 0.00830942880392737\n",
            "Epoch 67 Loss: 0.008037785023674191\n",
            "Epoch 68 Loss: 0.007771203316409706\n",
            "Epoch 69 Loss: 0.007510057221619122\n",
            "Epoch 70 Loss: 0.007254722292353154\n",
            "Epoch 71 Loss: 0.0070055531627621825\n",
            "Epoch 72 Loss: 0.006762880284017507\n",
            "Epoch 73 Loss: 0.0065270142147839\n",
            "Epoch 74 Loss: 0.006298218033383401\n",
            "Epoch 75 Loss: 0.006076743990105789\n",
            "Epoch 76 Loss: 0.005862777412850631\n",
            "Epoch 77 Loss: 0.005656478490713786\n",
            "Epoch 78 Loss: 0.005457953262517019\n",
            "Epoch 79 Loss: 0.005267274182469267\n",
            "Epoch 80 Loss: 0.005084456285952316\n",
            "Epoch 81 Loss: 0.004909490533778913\n",
            "Epoch 82 Loss: 0.004742325164313682\n",
            "Epoch 83 Loss: 0.004582855493525907\n",
            "Epoch 84 Loss: 0.004430958898229002\n",
            "Epoch 85 Loss: 0.0042864779428813836\n",
            "Epoch 86 Loss: 0.004149237246990748\n",
            "Epoch 87 Loss: 0.004019028602768829\n",
            "Epoch 88 Loss: 0.003895620458643275\n",
            "Epoch 89 Loss: 0.0037787731776471774\n",
            "Epoch 90 Loss: 0.003668229614445699\n",
            "Epoch 91 Loss: 0.0035637184597734884\n",
            "Epoch 92 Loss: 0.00346495598879765\n",
            "Epoch 93 Loss: 0.0033716578689248315\n",
            "Epoch 94 Loss: 0.0032835309533634552\n",
            "Epoch 95 Loss: 0.00320027711657718\n",
            "Epoch 96 Loss: 0.0031215995852320482\n",
            "Epoch 97 Loss: 0.0030472002748331574\n",
            "Epoch 98 Loss: 0.002976803878137424\n",
            "Epoch 99 Loss: 0.0029101211154882825\n",
            "Epoch 100 Loss: 0.002846886804016298\n",
            "Epoch 101 Loss: 0.0027868453812154147\n",
            "Epoch 102 Loss: 0.002729755474158112\n",
            "Epoch 103 Loss: 0.0026753954798202305\n",
            "Epoch 104 Loss: 0.002623544500224476\n",
            "Epoch 105 Loss: 0.0025740107750216986\n",
            "Epoch 106 Loss: 0.0025266131491721647\n",
            "Epoch 107 Loss: 0.0024811942234552603\n",
            "Epoch 108 Loss: 0.0024375987887220118\n",
            "Epoch 109 Loss: 0.002395687116403015\n",
            "Epoch 110 Loss: 0.002355339632258934\n",
            "Epoch 111 Loss: 0.0023164401148724387\n",
            "Epoch 112 Loss: 0.002278888631710701\n",
            "Epoch 113 Loss: 0.0022425899424780953\n",
            "Epoch 114 Loss: 0.0022074627119877607\n",
            "Epoch 115 Loss: 0.0021734300207724194\n",
            "Epoch 116 Loss: 0.0021404293797839015\n",
            "Epoch 117 Loss: 0.002108391030572666\n",
            "Epoch 118 Loss: 0.0020772621365406575\n",
            "Epoch 119 Loss: 0.0020469902694609707\n",
            "Epoch 120 Loss: 0.002017535118999414\n",
            "Epoch 121 Loss: 0.0019888462209559895\n",
            "Epoch 122 Loss: 0.0019608891572952757\n",
            "Epoch 123 Loss: 0.0019336290041303136\n",
            "Epoch 124 Loss: 0.0019070290996932848\n",
            "Epoch 125 Loss: 0.0018810671470516373\n",
            "Epoch 126 Loss: 0.0018557090292440172\n",
            "Epoch 127 Loss: 0.0018309290539067393\n",
            "Epoch 128 Loss: 0.001806707148574519\n",
            "Epoch 129 Loss: 0.0017830196766470694\n",
            "Epoch 130 Loss: 0.0017598422954642218\n",
            "Epoch 131 Loss: 0.0017371603048702289\n",
            "Epoch 132 Loss: 0.0017149549966626633\n",
            "Epoch 133 Loss: 0.0016932067960787889\n",
            "Epoch 134 Loss: 0.0016719005540495246\n",
            "Epoch 135 Loss: 0.0016510199884242586\n",
            "Epoch 136 Loss: 0.0016305513734058575\n",
            "Epoch 137 Loss: 0.0016104779860990346\n",
            "Epoch 138 Loss: 0.001590789762993187\n",
            "Epoch 139 Loss: 0.0015714757133246007\n",
            "Epoch 140 Loss: 0.0015525186932288668\n",
            "Epoch 141 Loss: 0.0015339080057040113\n",
            "Epoch 142 Loss: 0.001515632825330659\n",
            "Epoch 143 Loss: 0.0014976810855161064\n",
            "Epoch 144 Loss: 0.0014800438332880335\n",
            "Epoch 145 Loss: 0.0014627092341250052\n",
            "Epoch 146 Loss: 0.0014456658978540318\n",
            "Epoch 147 Loss: 0.0014289064500619373\n",
            "Epoch 148 Loss: 0.0014124189164601883\n",
            "Epoch 149 Loss: 0.0013961941743895737\n",
            "Epoch 150 Loss: 0.0013802208719642312\n",
            "Epoch 151 Loss: 0.001364494946864406\n",
            "Epoch 152 Loss: 0.0013490027848504806\n",
            "Epoch 153 Loss: 0.001333739225001392\n",
            "Epoch 154 Loss: 0.0013186916133574851\n",
            "Epoch 155 Loss: 0.001303853928671676\n",
            "Epoch 156 Loss: 0.0012892166596796195\n",
            "Epoch 157 Loss: 0.0012747734706447628\n",
            "Epoch 158 Loss: 0.0012605164187105096\n",
            "Epoch 159 Loss: 0.0012464363190063921\n",
            "Epoch 160 Loss: 0.0012325268486682941\n",
            "Epoch 161 Loss: 0.0012187797236177154\n",
            "Epoch 162 Loss: 0.0012051898567759256\n",
            "Epoch 163 Loss: 0.0011917509477627583\n",
            "Epoch 164 Loss: 0.0011784557506984638\n",
            "Epoch 165 Loss: 0.0011652992171520527\n",
            "Epoch 166 Loss: 0.0011522756258221826\n",
            "Epoch 167 Loss: 0.0011393827460589008\n",
            "Epoch 168 Loss: 0.0011266128194515506\n",
            "Epoch 169 Loss: 0.0011139626597261424\n",
            "Epoch 170 Loss: 0.0011014288633685203\n",
            "Epoch 171 Loss: 0.0010890080315699706\n",
            "Epoch 172 Loss: 0.0010766969548495484\n",
            "Epoch 173 Loss: 0.0010644970446090818\n",
            "Epoch 174 Loss: 0.0010524017233815846\n",
            "Epoch 175 Loss: 0.0010404123715357138\n",
            "Epoch 176 Loss: 0.0010285272366008064\n",
            "Epoch 177 Loss: 0.0010167480194999618\n",
            "Epoch 178 Loss: 0.0010050722866196485\n",
            "Epoch 179 Loss: 0.0009935039392880891\n",
            "Epoch 180 Loss: 0.0009820408412938514\n",
            "Epoch 181 Loss: 0.0009706892473453346\n",
            "Epoch 182 Loss: 0.0009594465647696362\n",
            "Epoch 183 Loss: 0.0009483192024978154\n",
            "Epoch 184 Loss: 0.0009373076477887493\n",
            "Epoch 185 Loss: 0.0009264164203238403\n",
            "Epoch 186 Loss: 0.0009156459845571986\n",
            "Epoch 187 Loss: 0.0009050017957957222\n",
            "Epoch 188 Loss: 0.000894489281342157\n",
            "Epoch 189 Loss: 0.0008841111059202812\n",
            "Epoch 190 Loss: 0.0008738700287818519\n",
            "Epoch 191 Loss: 0.0008637694146519387\n",
            "Epoch 192 Loss: 0.0008538162555901746\n",
            "Epoch 193 Loss: 0.0008440099728427892\n",
            "Epoch 194 Loss: 0.0008343550972853472\n",
            "Epoch 195 Loss: 0.0008248531266741642\n",
            "Epoch 196 Loss: 0.0008155098289713321\n",
            "Epoch 197 Loss: 0.0008063249517491043\n",
            "Epoch 198 Loss: 0.0007973010158340674\n",
            "Epoch 199 Loss: 0.0007884381041172637\n",
            "Epoch 200 Loss: 0.0007797388133547167\n",
            "Epoch 201 Loss: 0.0007712041041911538\n",
            "Epoch 202 Loss: 0.0007628313561143705\n",
            "Epoch 203 Loss: 0.0007546212278276694\n",
            "Epoch 204 Loss: 0.0007465758422428986\n",
            "Epoch 205 Loss: 0.0007386911534416784\n",
            "Epoch 206 Loss: 0.000730965684735717\n",
            "Epoch 207 Loss: 0.0007233982449609447\n",
            "Epoch 208 Loss: 0.0007159868040586701\n",
            "Epoch 209 Loss: 0.000708732143249412\n",
            "Epoch 210 Loss: 0.0007016275272674023\n",
            "Epoch 211 Loss: 0.0006946726759293377\n",
            "Epoch 212 Loss: 0.0006878662400339866\n",
            "Epoch 213 Loss: 0.0006812037509786527\n",
            "Epoch 214 Loss: 0.0006746850001856606\n",
            "Epoch 215 Loss: 0.0006683038078945047\n",
            "Epoch 216 Loss: 0.000662060612022184\n",
            "Epoch 217 Loss: 0.0006559520915389037\n",
            "Epoch 218 Loss: 0.0006499754917063417\n",
            "Epoch 219 Loss: 0.000644128914110565\n",
            "Epoch 220 Loss: 0.0006384093057424474\n",
            "Epoch 221 Loss: 0.000632813628044385\n",
            "Epoch 222 Loss: 0.0006273410123510643\n",
            "Epoch 223 Loss: 0.0006219903380010218\n",
            "Epoch 224 Loss: 0.0006167591267985925\n",
            "Epoch 225 Loss: 0.0006116431083687747\n",
            "Epoch 226 Loss: 0.000606643714986796\n",
            "Epoch 227 Loss: 0.0006017595396918717\n",
            "Epoch 228 Loss: 0.0005969869665442027\n",
            "Epoch 229 Loss: 0.0005923268030472082\n",
            "Epoch 230 Loss: 0.0005877753378764906\n",
            "Epoch 231 Loss: 0.0005833333208151736\n",
            "Epoch 232 Loss: 0.000579002371923361\n",
            "Epoch 233 Loss: 0.0005747806515504925\n",
            "Epoch 234 Loss: 0.0005706671683400115\n",
            "Epoch 235 Loss: 0.0005666619478050106\n",
            "Epoch 236 Loss: 0.0005627662143580053\n",
            "Epoch 237 Loss: 0.0005589799171283465\n",
            "Epoch 238 Loss: 0.0005553035239693988\n",
            "Epoch 239 Loss: 0.0005517380362300938\n",
            "Epoch 240 Loss: 0.0005482843542925338\n",
            "Epoch 241 Loss: 0.0005449445675872466\n",
            "Epoch 242 Loss: 0.0005417177770911079\n",
            "Epoch 243 Loss: 0.0005386066947149153\n",
            "Epoch 244 Loss: 0.0005356142389370343\n",
            "Epoch 245 Loss: 0.000532739529716135\n",
            "Epoch 246 Loss: 0.0005299841639505036\n",
            "Epoch 247 Loss: 0.0005273503433847375\n",
            "Epoch 248 Loss: 0.0005248352904522505\n",
            "Epoch 249 Loss: 0.0005224420239130504\n",
            "Epoch 250 Loss: 0.0005201683390570964\n",
            "Epoch 251 Loss: 0.000518012058892442\n",
            "Epoch 252 Loss: 0.0005159725366804606\n",
            "Epoch 253 Loss: 0.0005140433876806614\n",
            "Epoch 254 Loss: 0.0005122155739369369\n",
            "Epoch 255 Loss: 0.0005104849633061943\n",
            "Epoch 256 Loss: 0.0005088428225096691\n",
            "Epoch 257 Loss: 0.0005072763239588413\n",
            "Epoch 258 Loss: 0.0005057721962035054\n",
            "Epoch 259 Loss: 0.0005043180188552414\n",
            "Epoch 260 Loss: 0.0005028954580782137\n",
            "Epoch 261 Loss: 0.0005014947735430771\n",
            "Epoch 262 Loss: 0.0005000990702421979\n",
            "Epoch 263 Loss: 0.000498692273213891\n",
            "Epoch 264 Loss: 0.0004972626513588016\n",
            "Epoch 265 Loss: 0.0004958000858690069\n",
            "Epoch 266 Loss: 0.0004942950291281433\n",
            "Epoch 267 Loss: 0.0004927397651891835\n",
            "Epoch 268 Loss: 0.0004911282591086925\n",
            "Epoch 269 Loss: 0.0004894604957279451\n",
            "Epoch 270 Loss: 0.00048773729673153417\n",
            "Epoch 271 Loss: 0.0004859591595777586\n",
            "Epoch 272 Loss: 0.00048412917146845714\n",
            "Epoch 273 Loss: 0.0004822486128929011\n",
            "Epoch 274 Loss: 0.0004803274923269379\n",
            "Epoch 275 Loss: 0.00047836766997851505\n",
            "Epoch 276 Loss: 0.00047637550830938554\n",
            "Epoch 277 Loss: 0.0004743532206765825\n",
            "Epoch 278 Loss: 0.00047230995102571014\n",
            "Epoch 279 Loss: 0.00047024708155629435\n",
            "Epoch 280 Loss: 0.0004681687239576053\n",
            "Epoch 281 Loss: 0.0004660801381028027\n",
            "Epoch 282 Loss: 0.00046398160867490527\n",
            "Epoch 283 Loss: 0.0004618762549319093\n",
            "Epoch 284 Loss: 0.0004597708327738065\n",
            "Epoch 285 Loss: 0.00045766086495249996\n",
            "Epoch 286 Loss: 0.00045555236147250716\n",
            "Epoch 287 Loss: 0.000453444533976553\n",
            "Epoch 288 Loss: 0.0004513380961241465\n",
            "Epoch 289 Loss: 0.00044923255925314226\n",
            "Epoch 290 Loss: 0.0004471321674081442\n",
            "Epoch 291 Loss: 0.00044503586888627286\n",
            "Epoch 292 Loss: 0.00044294001555203244\n",
            "Epoch 293 Loss: 0.00044084711362986443\n",
            "Epoch 294 Loss: 0.00043875796734577305\n",
            "Epoch 295 Loss: 0.0004366747749316286\n",
            "Epoch 296 Loss: 0.0004345990270764321\n",
            "Epoch 297 Loss: 0.0004325268570862238\n",
            "Epoch 298 Loss: 0.0004304546722321611\n",
            "Epoch 299 Loss: 0.00042838340432720443\n",
            "Epoch 300 Loss: 0.00042631637975586796\n",
            "Epoch 301 Loss: 0.00042425034657077716\n",
            "Epoch 302 Loss: 0.00042219054221820314\n",
            "Epoch 303 Loss: 0.0004201325403876575\n",
            "Epoch 304 Loss: 0.0004180765413381022\n",
            "Epoch 305 Loss: 0.00041602186219194537\n",
            "Epoch 306 Loss: 0.00041396691432632834\n",
            "Epoch 307 Loss: 0.00041191238729558526\n",
            "Epoch 308 Loss: 0.00040986136085725936\n",
            "Epoch 309 Loss: 0.00040781062599458444\n",
            "Epoch 310 Loss: 0.0004057599909264382\n",
            "Epoch 311 Loss: 0.00040371054026055965\n",
            "Epoch 312 Loss: 0.0004016620418406907\n",
            "Epoch 313 Loss: 0.00039961549603229643\n",
            "Epoch 314 Loss: 0.0003975674018051862\n",
            "Epoch 315 Loss: 0.000395520078982289\n",
            "Epoch 316 Loss: 0.0003934778356366957\n",
            "Epoch 317 Loss: 0.00039143931639300575\n",
            "Epoch 318 Loss: 0.00038940350811130685\n",
            "Epoch 319 Loss: 0.00038737151789643994\n",
            "Epoch 320 Loss: 0.0003853455896784304\n",
            "Epoch 321 Loss: 0.0003833284885862128\n",
            "Epoch 322 Loss: 0.00038131677611275743\n",
            "Epoch 323 Loss: 0.0003793123133231842\n",
            "Epoch 324 Loss: 0.0003773178348205803\n",
            "Epoch 325 Loss: 0.00037533841383150576\n",
            "Epoch 326 Loss: 0.0003733738092317283\n",
            "Epoch 327 Loss: 0.0003714250672788673\n",
            "Epoch 328 Loss: 0.0003694947055983454\n",
            "Epoch 329 Loss: 0.00036758599093615645\n",
            "Epoch 330 Loss: 0.00036569541093971696\n",
            "Epoch 331 Loss: 0.00036382998218820905\n",
            "Epoch 332 Loss: 0.0003619890095797832\n",
            "Epoch 333 Loss: 0.0003601744243990121\n",
            "Epoch 334 Loss: 0.0003583890359025417\n",
            "Epoch 335 Loss: 0.00035663215389051156\n",
            "Epoch 336 Loss: 0.00035490797510506447\n",
            "Epoch 337 Loss: 0.0003532150394266683\n",
            "Epoch 338 Loss: 0.00035155208053237584\n",
            "Epoch 339 Loss: 0.0003499229346817419\n",
            "Epoch 340 Loss: 0.000348327685185612\n",
            "Epoch 341 Loss: 0.0003467665531993555\n",
            "Epoch 342 Loss: 0.0003452386144803736\n",
            "Epoch 343 Loss: 0.00034374218003967416\n",
            "Epoch 344 Loss: 0.0003422804100023016\n",
            "Epoch 345 Loss: 0.00034084963492175997\n",
            "Epoch 346 Loss: 0.0003394471438887211\n",
            "Epoch 347 Loss: 0.0003380739595147482\n",
            "Epoch 348 Loss: 0.00033672860955550596\n",
            "Epoch 349 Loss: 0.00033540956489948553\n",
            "Epoch 350 Loss: 0.00033411669347135946\n",
            "Epoch 351 Loss: 0.0003328467409881011\n",
            "Epoch 352 Loss: 0.00033160170511692985\n",
            "Epoch 353 Loss: 0.0003303770892939877\n",
            "Epoch 354 Loss: 0.0003291744035375306\n",
            "Epoch 355 Loss: 0.0003279903453618569\n",
            "Epoch 356 Loss: 0.00032682099815142243\n",
            "Epoch 357 Loss: 0.00032566548403075286\n",
            "Epoch 358 Loss: 0.00032452713275051476\n",
            "Epoch 359 Loss: 0.00032340272530535595\n",
            "Epoch 360 Loss: 0.00032229485217004773\n",
            "Epoch 361 Loss: 0.00032119733489217964\n",
            "Epoch 362 Loss: 0.0003201084539773542\n",
            "Epoch 363 Loss: 0.00031903023746063713\n",
            "Epoch 364 Loss: 0.0003179608015993087\n",
            "Epoch 365 Loss: 0.0003168985358078806\n",
            "Epoch 366 Loss: 0.00031584542202259133\n",
            "Epoch 367 Loss: 0.0003148031229600992\n",
            "Epoch 368 Loss: 0.00031376737257212463\n",
            "Epoch 369 Loss: 0.000312736704222465\n",
            "Epoch 370 Loss: 0.00031171437899498724\n",
            "Epoch 371 Loss: 0.00031069731486944483\n",
            "Epoch 372 Loss: 0.0003096840001519561\n",
            "Epoch 373 Loss: 0.00030867599667402994\n",
            "Epoch 374 Loss: 0.00030767507396374413\n",
            "Epoch 375 Loss: 0.00030667747369153976\n",
            "Epoch 376 Loss: 0.0003056836036193522\n",
            "Epoch 377 Loss: 0.00030469755621983754\n",
            "Epoch 378 Loss: 0.00030371573060075955\n",
            "Epoch 379 Loss: 0.00030273747211159203\n",
            "Epoch 380 Loss: 0.0003017633262276506\n",
            "Epoch 381 Loss: 0.00030079383376473417\n",
            "Epoch 382 Loss: 0.00029983090701533465\n",
            "Epoch 383 Loss: 0.0002988721080873361\n",
            "Epoch 384 Loss: 0.0002979142261928615\n",
            "Epoch 385 Loss: 0.0002969598889509329\n",
            "Epoch 386 Loss: 0.0002960106299313412\n",
            "Epoch 387 Loss: 0.0002950679609426802\n",
            "Epoch 388 Loss: 0.0002941277124823836\n",
            "Epoch 389 Loss: 0.0002931927695920162\n",
            "Epoch 390 Loss: 0.00029225901537909926\n",
            "Epoch 391 Loss: 0.00029132953585879045\n",
            "Epoch 392 Loss: 0.0002904068617790771\n",
            "Epoch 393 Loss: 0.0002894851891330043\n",
            "Epoch 394 Loss: 0.0002885665953625837\n",
            "Epoch 395 Loss: 0.0002876537124490532\n",
            "Epoch 396 Loss: 0.00028674131399521657\n",
            "Epoch 397 Loss: 0.0002858338794938889\n",
            "Epoch 398 Loss: 0.00028492881273548085\n",
            "Epoch 399 Loss: 0.00028402643240332614\n",
            "Epoch 400 Loss: 0.0002831273796208151\n",
            "Epoch 401 Loss: 0.00028222945231819527\n",
            "Epoch 402 Loss: 0.00028133329724111484\n",
            "Epoch 403 Loss: 0.00028044151441888394\n",
            "Epoch 404 Loss: 0.0002795519338064075\n",
            "Epoch 405 Loss: 0.000278666893165279\n",
            "Epoch 406 Loss: 0.00027778159434737015\n",
            "Epoch 407 Loss: 0.000276896495130981\n",
            "Epoch 408 Loss: 0.00027601036275269483\n",
            "Epoch 409 Loss: 0.0002751258302211947\n",
            "Epoch 410 Loss: 0.00027424330627836717\n",
            "Epoch 411 Loss: 0.0002733616057070704\n",
            "Epoch 412 Loss: 0.0002724795710565111\n",
            "Epoch 413 Loss: 0.0002715956595186122\n",
            "Epoch 414 Loss: 0.0002707118937166531\n",
            "Epoch 415 Loss: 0.0002698267158546257\n",
            "Epoch 416 Loss: 0.0002689404850137938\n",
            "Epoch 417 Loss: 0.0002680517248515385\n",
            "Epoch 418 Loss: 0.0002671616243467956\n",
            "Epoch 419 Loss: 0.00026626911766243873\n",
            "Epoch 420 Loss: 0.0002653695697907586\n",
            "Epoch 421 Loss: 0.00026446697832566764\n",
            "Epoch 422 Loss: 0.0002635605601971508\n",
            "Epoch 423 Loss: 0.00026264908888751275\n",
            "Epoch 424 Loss: 0.0002617334293106984\n",
            "Epoch 425 Loss: 0.00026080793256250264\n",
            "Epoch 426 Loss: 0.00025987422206876556\n",
            "Epoch 427 Loss: 0.0002589348677614566\n",
            "Epoch 428 Loss: 0.00025798417600885\n",
            "Epoch 429 Loss: 0.0002570219267972978\n",
            "Epoch 430 Loss: 0.00025605177264541226\n",
            "Epoch 431 Loss: 0.00025506843968516307\n",
            "Epoch 432 Loss: 0.00025406972130535436\n",
            "Epoch 433 Loss: 0.00025305809688184436\n",
            "Epoch 434 Loss: 0.00025202790856673047\n",
            "Epoch 435 Loss: 0.0002509821325125062\n",
            "Epoch 436 Loss: 0.0002499169217535391\n",
            "Epoch 437 Loss: 0.00024883023426894974\n",
            "Epoch 438 Loss: 0.0002477219007801467\n",
            "Epoch 439 Loss: 0.0002465923594668026\n",
            "Epoch 440 Loss: 0.00024543402550849174\n",
            "Epoch 441 Loss: 0.000244247651076361\n",
            "Epoch 442 Loss: 0.00024303317012208808\n",
            "Epoch 443 Loss: 0.00024178555363381913\n",
            "Epoch 444 Loss: 0.00024050148268998182\n",
            "Epoch 445 Loss: 0.00023918373758447266\n",
            "Epoch 446 Loss: 0.00023782601045304165\n",
            "Epoch 447 Loss: 0.00023642435631990636\n",
            "Epoch 448 Loss: 0.00023497918053837046\n",
            "Epoch 449 Loss: 0.00023348701056194994\n",
            "Epoch 450 Loss: 0.0002319443348440942\n",
            "Epoch 451 Loss: 0.00023035039942277514\n",
            "Epoch 452 Loss: 0.00022870169680519025\n",
            "Epoch 453 Loss: 0.0002269979380337937\n",
            "Epoch 454 Loss: 0.00022523710520085992\n",
            "Epoch 455 Loss: 0.00022341707781335868\n",
            "Epoch 456 Loss: 0.00022153829539953368\n",
            "Epoch 457 Loss: 0.00021959898222773553\n",
            "Epoch 458 Loss: 0.0002175986921556991\n",
            "Epoch 459 Loss: 0.00021554230201286954\n",
            "Epoch 460 Loss: 0.0002134301293263821\n",
            "Epoch 461 Loss: 0.00021126606325487027\n",
            "Epoch 462 Loss: 0.0002090580259121644\n",
            "Epoch 463 Loss: 0.00020681279455390697\n",
            "Epoch 464 Loss: 0.00020453836664720734\n",
            "Epoch 465 Loss: 0.00020224488617177962\n",
            "Epoch 466 Loss: 0.00019994456265501486\n",
            "Epoch 467 Loss: 0.00019764661690577204\n",
            "Epoch 468 Loss: 0.0001953662964839729\n",
            "Epoch 469 Loss: 0.00019311481255216347\n",
            "Epoch 470 Loss: 0.00019090597503614655\n",
            "Epoch 471 Loss: 0.000188752193761305\n",
            "Epoch 472 Loss: 0.0001866665934906754\n",
            "Epoch 473 Loss: 0.00018465618603523152\n",
            "Epoch 474 Loss: 0.000182729471877351\n",
            "Epoch 475 Loss: 0.00018089267309308633\n",
            "Epoch 476 Loss: 0.00017914689832309853\n",
            "Epoch 477 Loss: 0.00017749327256433195\n",
            "Epoch 478 Loss: 0.00017593182369646883\n",
            "Epoch 479 Loss: 0.00017445737863890586\n",
            "Epoch 480 Loss: 0.0001730677888573169\n",
            "Epoch 481 Loss: 0.00017175718662771703\n",
            "Epoch 482 Loss: 0.0001705184656761982\n",
            "Epoch 483 Loss: 0.00016934462733751056\n",
            "Epoch 484 Loss: 0.00016823256292359656\n",
            "Epoch 485 Loss: 0.0001671754712579698\n",
            "Epoch 486 Loss: 0.00016616650892316254\n",
            "Epoch 487 Loss: 0.000165200727300899\n",
            "Epoch 488 Loss: 0.00016427428786683598\n",
            "Epoch 489 Loss: 0.00016338047109646368\n",
            "Epoch 490 Loss: 0.00016251999239079367\n",
            "Epoch 491 Loss: 0.0001616869943410654\n",
            "Epoch 492 Loss: 0.00016087601506706447\n",
            "Epoch 493 Loss: 0.00016008804458933766\n",
            "Epoch 494 Loss: 0.0001593180144876218\n",
            "Epoch 495 Loss: 0.00015856389239860726\n",
            "Epoch 496 Loss: 0.00015782567993036567\n",
            "Epoch 497 Loss: 0.00015710055612116322\n",
            "Epoch 498 Loss: 0.0001563861351522305\n",
            "Epoch 499 Loss: 0.00015568139761300387\n",
            "Epoch 500 Loss: 0.00015498673545449277\n",
            "Epoch 501 Loss: 0.00015429747951134214\n",
            "Epoch 502 Loss: 0.00015361445053977557\n",
            "Epoch 503 Loss: 0.0001529375546567125\n",
            "Epoch 504 Loss: 0.00015226544214271443\n",
            "Epoch 505 Loss: 0.00015159635978090102\n",
            "Epoch 506 Loss: 0.0001509298887389316\n",
            "Epoch 507 Loss: 0.00015026706666412828\n",
            "Epoch 508 Loss: 0.00014960608265971687\n",
            "Epoch 509 Loss: 0.00014894484139433957\n",
            "Epoch 510 Loss: 0.00014828687083423854\n",
            "Epoch 511 Loss: 0.00014762995265109175\n",
            "Epoch 512 Loss: 0.00014696886567336828\n",
            "Epoch 513 Loss: 0.000146310601929359\n",
            "Epoch 514 Loss: 0.00014565322556472354\n",
            "Epoch 515 Loss: 0.00014499405464481652\n",
            "Epoch 516 Loss: 0.00014433186460855664\n",
            "Epoch 517 Loss: 0.00014367118356452605\n",
            "Epoch 518 Loss: 0.0001430104288828044\n",
            "Epoch 519 Loss: 0.00014234842858354432\n",
            "Epoch 520 Loss: 0.0001416855128278939\n",
            "Epoch 521 Loss: 0.0001410209043201861\n",
            "Epoch 522 Loss: 0.0001403551941473396\n",
            "Epoch 523 Loss: 0.00013968918453190662\n",
            "Epoch 524 Loss: 0.00013902285874647596\n",
            "Epoch 525 Loss: 0.00013835701237033355\n",
            "Epoch 526 Loss: 0.00013768905245241823\n",
            "Epoch 527 Loss: 0.00013702101250789652\n",
            "Epoch 528 Loss: 0.0001363541664799903\n",
            "Epoch 529 Loss: 0.00013568787195664993\n",
            "Epoch 530 Loss: 0.00013502192201473098\n",
            "Epoch 531 Loss: 0.00013435639395794062\n",
            "Epoch 532 Loss: 0.0001336909250737203\n",
            "Epoch 533 Loss: 0.00013303028474470957\n",
            "Epoch 534 Loss: 0.00013237226091532815\n",
            "Epoch 535 Loss: 0.00013171581331025136\n",
            "Epoch 536 Loss: 0.0001310610232859702\n",
            "Epoch 537 Loss: 0.0001304099400656302\n",
            "Epoch 538 Loss: 0.0001297619959345907\n",
            "Epoch 539 Loss: 0.00012912042810981546\n",
            "Epoch 540 Loss: 0.00012848234379939742\n",
            "Epoch 541 Loss: 0.00012784982163025602\n",
            "Epoch 542 Loss: 0.00012722158206476177\n",
            "Epoch 543 Loss: 0.00012659931933568447\n",
            "Epoch 544 Loss: 0.00012598411039260396\n",
            "Epoch 545 Loss: 0.00012537630749540104\n",
            "Epoch 546 Loss: 0.00012477556923431914\n",
            "Epoch 547 Loss: 0.00012418186761662078\n",
            "Epoch 548 Loss: 0.00012359739232848085\n",
            "Epoch 549 Loss: 0.00012302145740179744\n",
            "Epoch 550 Loss: 0.00012245714689430263\n",
            "Epoch 551 Loss: 0.0001219027174336353\n",
            "Epoch 552 Loss: 0.00012135970570706595\n",
            "Epoch 553 Loss: 0.00012082891978201495\n",
            "Epoch 554 Loss: 0.00012031182022100744\n",
            "Epoch 555 Loss: 0.00011980990278455098\n",
            "Epoch 556 Loss: 0.00011932563521155285\n",
            "Epoch 557 Loss: 0.0001188573878707091\n",
            "Epoch 558 Loss: 0.0001184069516084114\n",
            "Epoch 559 Loss: 0.00011797797520004893\n",
            "Epoch 560 Loss: 0.00011756862193098025\n",
            "Epoch 561 Loss: 0.00011718241857138693\n",
            "Epoch 562 Loss: 0.00011681879540883791\n",
            "Epoch 563 Loss: 0.00011647638170427432\n",
            "Epoch 564 Loss: 0.00011615193446417976\n",
            "Epoch 565 Loss: 0.00011584460948292966\n",
            "Epoch 566 Loss: 0.00011554953363929027\n",
            "Epoch 567 Loss: 0.00011526153480869088\n",
            "Epoch 568 Loss: 0.00011497408545085212\n",
            "Epoch 569 Loss: 0.00011468010167526889\n",
            "Epoch 570 Loss: 0.00011437567763403297\n",
            "Epoch 571 Loss: 0.00011405533961699234\n",
            "Epoch 572 Loss: 0.00011371617669255002\n",
            "Epoch 573 Loss: 0.00011335426351756474\n",
            "Epoch 574 Loss: 0.00011296996724310979\n",
            "Epoch 575 Loss: 0.00011256249996237941\n",
            "Epoch 576 Loss: 0.00011213488370808874\n",
            "Epoch 577 Loss: 0.00011168807510462455\n",
            "Epoch 578 Loss: 0.00011122541311925866\n",
            "Epoch 579 Loss: 0.0001107475664583315\n",
            "Epoch 580 Loss: 0.00011025793359622508\n",
            "Epoch 581 Loss: 0.00010976021914116322\n",
            "Epoch 582 Loss: 0.00010925478970930708\n",
            "Epoch 583 Loss: 0.00010874478252834284\n",
            "Epoch 584 Loss: 0.00010823276601464358\n",
            "Epoch 585 Loss: 0.00010771871043226292\n",
            "Epoch 586 Loss: 0.00010720454298536258\n",
            "Epoch 587 Loss: 0.00010668938910427894\n",
            "Epoch 588 Loss: 0.0001061774492439013\n",
            "Epoch 589 Loss: 0.00010566904764416423\n",
            "Epoch 590 Loss: 0.0001051661809717058\n",
            "Epoch 591 Loss: 0.00010466804665035115\n",
            "Epoch 592 Loss: 0.00010417611127037615\n",
            "Epoch 593 Loss: 0.00010369108770862886\n",
            "Epoch 594 Loss: 0.00010321406340120228\n",
            "Epoch 595 Loss: 0.00010274394442897954\n",
            "Epoch 596 Loss: 0.00010228167250034032\n",
            "Epoch 597 Loss: 0.00010182707610781798\n",
            "Epoch 598 Loss: 0.00010138093181025947\n",
            "Epoch 599 Loss: 0.00010094343668777099\n",
            "Epoch 600 Loss: 0.0001005149190934099\n",
            "Epoch 601 Loss: 0.00010009443863551502\n",
            "Epoch 602 Loss: 9.968367966043408e-05\n",
            "Epoch 603 Loss: 9.928091766399675e-05\n",
            "Epoch 604 Loss: 9.88861337178803e-05\n",
            "Epoch 605 Loss: 9.849971576241636e-05\n",
            "Epoch 606 Loss: 9.812168238511325e-05\n",
            "Epoch 607 Loss: 9.775074458369633e-05\n",
            "Epoch 608 Loss: 9.738965469993845e-05\n",
            "Epoch 609 Loss: 9.70363605969568e-05\n",
            "Epoch 610 Loss: 9.669046107929403e-05\n",
            "Epoch 611 Loss: 9.635104080072953e-05\n",
            "Epoch 612 Loss: 9.602084729147662e-05\n",
            "Epoch 613 Loss: 9.569550705712141e-05\n",
            "Epoch 614 Loss: 9.538004931293306e-05\n",
            "Epoch 615 Loss: 9.507091162661724e-05\n",
            "Epoch 616 Loss: 9.476981521065183e-05\n",
            "Epoch 617 Loss: 9.447513416829257e-05\n",
            "Epoch 618 Loss: 9.418550050718665e-05\n",
            "Epoch 619 Loss: 9.390420661614196e-05\n",
            "Epoch 620 Loss: 9.363087832093421e-05\n",
            "Epoch 621 Loss: 9.336034483617113e-05\n",
            "Epoch 622 Loss: 9.309708543921769e-05\n",
            "Epoch 623 Loss: 9.283830812022681e-05\n",
            "Epoch 624 Loss: 9.258313584880918e-05\n",
            "Epoch 625 Loss: 9.23339034638703e-05\n",
            "Epoch 626 Loss: 9.208747066759394e-05\n",
            "Epoch 627 Loss: 9.184398241236079e-05\n",
            "Epoch 628 Loss: 9.160278244386246e-05\n",
            "Epoch 629 Loss: 9.136275859784609e-05\n",
            "Epoch 630 Loss: 9.112486126946746e-05\n",
            "Epoch 631 Loss: 9.088587564313136e-05\n",
            "Epoch 632 Loss: 9.064628302243127e-05\n",
            "Epoch 633 Loss: 9.040527162695292e-05\n",
            "Epoch 634 Loss: 9.01607792350043e-05\n",
            "Epoch 635 Loss: 8.991761175373405e-05\n",
            "Epoch 636 Loss: 8.967111812843304e-05\n",
            "Epoch 637 Loss: 8.941847440988384e-05\n",
            "Epoch 638 Loss: 8.916190523927426e-05\n",
            "Epoch 639 Loss: 8.890212879115183e-05\n",
            "Epoch 640 Loss: 8.863625412770263e-05\n",
            "Epoch 641 Loss: 8.837062199458863e-05\n",
            "Epoch 642 Loss: 8.809873686897035e-05\n",
            "Epoch 643 Loss: 8.782466974047158e-05\n",
            "Epoch 644 Loss: 8.754441767640812e-05\n",
            "Epoch 645 Loss: 8.726083668135271e-05\n",
            "Epoch 646 Loss: 8.697487148398433e-05\n",
            "Epoch 647 Loss: 8.668587175406557e-05\n",
            "Epoch 648 Loss: 8.63945672458397e-05\n",
            "Epoch 649 Loss: 8.610110604668992e-05\n",
            "Epoch 650 Loss: 8.580326386684835e-05\n",
            "Epoch 651 Loss: 8.550619330749392e-05\n",
            "Epoch 652 Loss: 8.520603502639357e-05\n",
            "Epoch 653 Loss: 8.490656026016967e-05\n",
            "Epoch 654 Loss: 8.460608401887214e-05\n",
            "Epoch 655 Loss: 8.430471914909372e-05\n",
            "Epoch 656 Loss: 8.400422678694662e-05\n",
            "Epoch 657 Loss: 8.370318308128685e-05\n",
            "Epoch 658 Loss: 8.340142022245979e-05\n",
            "Epoch 659 Loss: 8.310207299730704e-05\n",
            "Epoch 660 Loss: 8.280141419667843e-05\n",
            "Epoch 661 Loss: 8.250054013338543e-05\n",
            "Epoch 662 Loss: 8.220137003227089e-05\n",
            "Epoch 663 Loss: 8.190331564796872e-05\n",
            "Epoch 664 Loss: 8.160607677979989e-05\n",
            "Epoch 665 Loss: 8.130923612286698e-05\n",
            "Epoch 666 Loss: 8.101243355224608e-05\n",
            "Epoch 667 Loss: 8.071998778787833e-05\n",
            "Epoch 668 Loss: 8.042588658553554e-05\n",
            "Epoch 669 Loss: 8.013575468571853e-05\n",
            "Epoch 670 Loss: 7.984389879796843e-05\n",
            "Epoch 671 Loss: 7.955494094542442e-05\n",
            "Epoch 672 Loss: 7.926536232514082e-05\n",
            "Epoch 673 Loss: 7.897619626190561e-05\n",
            "Epoch 674 Loss: 7.868851490888364e-05\n",
            "Epoch 675 Loss: 7.8400979930864e-05\n",
            "Epoch 676 Loss: 7.811615818260988e-05\n",
            "Epoch 677 Loss: 7.783399429935907e-05\n",
            "Epoch 678 Loss: 7.755349587793249e-05\n",
            "Epoch 679 Loss: 7.727170249714758e-05\n",
            "Epoch 680 Loss: 7.69921899498841e-05\n",
            "Epoch 681 Loss: 7.671276563371195e-05\n",
            "Epoch 682 Loss: 7.643557880867962e-05\n",
            "Epoch 683 Loss: 7.615849191358831e-05\n",
            "Epoch 684 Loss: 7.587949577222289e-05\n",
            "Epoch 685 Loss: 7.560795680204803e-05\n",
            "Epoch 686 Loss: 7.533192316276138e-05\n",
            "Epoch 687 Loss: 7.505882499739021e-05\n",
            "Epoch 688 Loss: 7.479090237261697e-05\n",
            "Epoch 689 Loss: 7.451977998277671e-05\n",
            "Epoch 690 Loss: 7.425179308358549e-05\n",
            "Epoch 691 Loss: 7.398457376013762e-05\n",
            "Epoch 692 Loss: 7.371804042339155e-05\n",
            "Epoch 693 Loss: 7.345277467083699e-05\n",
            "Epoch 694 Loss: 7.319044666606555e-05\n",
            "Epoch 695 Loss: 7.292842744083348e-05\n",
            "Epoch 696 Loss: 7.266761724386882e-05\n",
            "Epoch 697 Loss: 7.240803151705012e-05\n",
            "Epoch 698 Loss: 7.214910691052598e-05\n",
            "Epoch 699 Loss: 7.189139711642653e-05\n",
            "Epoch 700 Loss: 7.16343644533385e-05\n",
            "Epoch 701 Loss: 7.137841984690188e-05\n",
            "Epoch 702 Loss: 7.112449389550756e-05\n",
            "Epoch 703 Loss: 7.087116639806132e-05\n",
            "Epoch 704 Loss: 7.061881394973358e-05\n",
            "Epoch 705 Loss: 7.036970905839107e-05\n",
            "Epoch 706 Loss: 7.012128305228581e-05\n",
            "Epoch 707 Loss: 6.987286262202883e-05\n",
            "Epoch 708 Loss: 6.962866470472525e-05\n",
            "Epoch 709 Loss: 6.938594361553082e-05\n",
            "Epoch 710 Loss: 6.914248435657471e-05\n",
            "Epoch 711 Loss: 6.890158583383954e-05\n",
            "Epoch 712 Loss: 6.866210507725823e-05\n",
            "Epoch 713 Loss: 6.84215695561588e-05\n",
            "Epoch 714 Loss: 6.818549923798171e-05\n",
            "Epoch 715 Loss: 6.794844171587154e-05\n",
            "Epoch 716 Loss: 6.77150042740919e-05\n",
            "Epoch 717 Loss: 6.748176245173525e-05\n",
            "Epoch 718 Loss: 6.724592469147608e-05\n",
            "Epoch 719 Loss: 6.701807516920991e-05\n",
            "Epoch 720 Loss: 6.678675308248283e-05\n",
            "Epoch 721 Loss: 6.655821083935361e-05\n",
            "Epoch 722 Loss: 6.633366729909679e-05\n",
            "Epoch 723 Loss: 6.610885173428145e-05\n",
            "Epoch 724 Loss: 6.588745797855753e-05\n",
            "Epoch 725 Loss: 6.566683273034601e-05\n",
            "Epoch 726 Loss: 6.544664621651549e-05\n",
            "Epoch 727 Loss: 6.522925065417108e-05\n",
            "Epoch 728 Loss: 6.501292865253288e-05\n",
            "Epoch 729 Loss: 6.479994089287934e-05\n",
            "Epoch 730 Loss: 6.45836064701484e-05\n",
            "Epoch 731 Loss: 6.437141677637505e-05\n",
            "Epoch 732 Loss: 6.416080743986921e-05\n",
            "Epoch 733 Loss: 6.395238508852267e-05\n",
            "Epoch 734 Loss: 6.374577163134903e-05\n",
            "Epoch 735 Loss: 6.353797981238136e-05\n",
            "Epoch 736 Loss: 6.333414918594219e-05\n",
            "Epoch 737 Loss: 6.31322049993509e-05\n",
            "Epoch 738 Loss: 6.293109623441303e-05\n",
            "Epoch 739 Loss: 6.273219413207526e-05\n",
            "Epoch 740 Loss: 6.253455321817047e-05\n",
            "Epoch 741 Loss: 6.233730985944786e-05\n",
            "Epoch 742 Loss: 6.214294877610666e-05\n",
            "Epoch 743 Loss: 6.194905247857392e-05\n",
            "Epoch 744 Loss: 6.175455756895073e-05\n",
            "Epoch 745 Loss: 6.156473873154681e-05\n",
            "Epoch 746 Loss: 6.137667194415534e-05\n",
            "Epoch 747 Loss: 6.118791858757865e-05\n",
            "Epoch 748 Loss: 6.100111771755687e-05\n",
            "Epoch 749 Loss: 6.081869769473896e-05\n",
            "Epoch 750 Loss: 6.0636428010997745e-05\n",
            "Epoch 751 Loss: 6.045506241025433e-05\n",
            "Epoch 752 Loss: 6.027474218909186e-05\n",
            "Epoch 753 Loss: 6.009609314927755e-05\n",
            "Epoch 754 Loss: 5.9921172121268137e-05\n",
            "Epoch 755 Loss: 5.974472323948222e-05\n",
            "Epoch 756 Loss: 5.956881887436037e-05\n",
            "Epoch 757 Loss: 5.9395382067284294e-05\n",
            "Epoch 758 Loss: 5.922193592992552e-05\n",
            "Epoch 759 Loss: 5.90493190695119e-05\n",
            "Epoch 760 Loss: 5.887824623922216e-05\n",
            "Epoch 761 Loss: 5.871106659618533e-05\n",
            "Epoch 762 Loss: 5.8544172207174194e-05\n",
            "Epoch 763 Loss: 5.8380105050955456e-05\n",
            "Epoch 764 Loss: 5.821693054953057e-05\n",
            "Epoch 765 Loss: 5.805241410117989e-05\n",
            "Epoch 766 Loss: 5.789140047975098e-05\n",
            "Epoch 767 Loss: 5.773207291916976e-05\n",
            "Epoch 768 Loss: 5.757149382418873e-05\n",
            "Epoch 769 Loss: 5.741356149844096e-05\n",
            "Epoch 770 Loss: 5.7257897664404354e-05\n",
            "Epoch 771 Loss: 5.709986898059301e-05\n",
            "Epoch 772 Loss: 5.694501319569291e-05\n",
            "Epoch 773 Loss: 5.6792117135980854e-05\n",
            "Epoch 774 Loss: 5.6638580273786584e-05\n",
            "Epoch 775 Loss: 5.648640674716344e-05\n",
            "Epoch 776 Loss: 5.633643142650012e-05\n",
            "Epoch 777 Loss: 5.6188802570768054e-05\n",
            "Epoch 778 Loss: 5.603858681255206e-05\n",
            "Epoch 779 Loss: 5.589039160865209e-05\n",
            "Epoch 780 Loss: 5.574415509115497e-05\n",
            "Epoch 781 Loss: 5.559869640660045e-05\n",
            "Epoch 782 Loss: 5.545364301970591e-05\n",
            "Epoch 783 Loss: 5.5310465974103816e-05\n",
            "Epoch 784 Loss: 5.5167925856096206e-05\n",
            "Epoch 785 Loss: 5.5025035518723856e-05\n",
            "Epoch 786 Loss: 5.4884946164881895e-05\n",
            "Epoch 787 Loss: 5.4746130694545403e-05\n",
            "Epoch 788 Loss: 5.460713345249157e-05\n",
            "Epoch 789 Loss: 5.447043665304767e-05\n",
            "Epoch 790 Loss: 5.4333592560911935e-05\n",
            "Epoch 791 Loss: 5.4197554784592475e-05\n",
            "Epoch 792 Loss: 5.4061313018273244e-05\n",
            "Epoch 793 Loss: 5.392852660196672e-05\n",
            "Epoch 794 Loss: 5.3793929998394055e-05\n",
            "Epoch 795 Loss: 5.3660484865469096e-05\n",
            "Epoch 796 Loss: 5.3530076845351755e-05\n",
            "Epoch 797 Loss: 5.339905776067129e-05\n",
            "Epoch 798 Loss: 5.3267904898827036e-05\n",
            "Epoch 799 Loss: 5.313925355791035e-05\n",
            "Epoch 800 Loss: 5.3010594412669655e-05\n",
            "Epoch 801 Loss: 5.288084883585622e-05\n",
            "Epoch 802 Loss: 5.275279697695076e-05\n",
            "Epoch 803 Loss: 5.262747913142372e-05\n",
            "Epoch 804 Loss: 5.2499832724054276e-05\n",
            "Epoch 805 Loss: 5.237622101125087e-05\n",
            "Epoch 806 Loss: 5.225297723965788e-05\n",
            "Epoch 807 Loss: 5.2130774194727855e-05\n",
            "Epoch 808 Loss: 5.200844386547593e-05\n",
            "Epoch 809 Loss: 5.188761216903193e-05\n",
            "Epoch 810 Loss: 5.1766965751921974e-05\n",
            "Epoch 811 Loss: 5.1646522898475035e-05\n",
            "Epoch 812 Loss: 5.1525594454239785e-05\n",
            "Epoch 813 Loss: 5.1407762985939454e-05\n",
            "Epoch 814 Loss: 5.1289323080190825e-05\n",
            "Epoch 815 Loss: 5.117293626854706e-05\n",
            "Epoch 816 Loss: 5.10557306091037e-05\n",
            "Epoch 817 Loss: 5.09397943754103e-05\n",
            "Epoch 818 Loss: 5.08231887870363e-05\n",
            "Epoch 819 Loss: 5.0708881341450704e-05\n",
            "Epoch 820 Loss: 5.059492277254497e-05\n",
            "Epoch 821 Loss: 5.048288029062452e-05\n",
            "Epoch 822 Loss: 5.0371959023153055e-05\n",
            "Epoch 823 Loss: 5.0260096698390265e-05\n",
            "Epoch 824 Loss: 5.014604238240221e-05\n",
            "Epoch 825 Loss: 5.003715104431973e-05\n",
            "Epoch 826 Loss: 4.9928576954128706e-05\n",
            "Epoch 827 Loss: 4.981936393543406e-05\n",
            "Epoch 828 Loss: 4.9709794062817366e-05\n",
            "Epoch 829 Loss: 4.9600489340601506e-05\n",
            "Epoch 830 Loss: 4.949590195973193e-05\n",
            "Epoch 831 Loss: 4.9393062189547734e-05\n",
            "Epoch 832 Loss: 4.928851390812454e-05\n",
            "Epoch 833 Loss: 4.918383968558235e-05\n",
            "Epoch 834 Loss: 4.9081126583619054e-05\n",
            "Epoch 835 Loss: 4.897733543400055e-05\n",
            "Epoch 836 Loss: 4.8874620271289206e-05\n",
            "Epoch 837 Loss: 4.8774090639572776e-05\n",
            "Epoch 838 Loss: 4.867292936210435e-05\n",
            "Epoch 839 Loss: 4.85740220935643e-05\n",
            "Epoch 840 Loss: 4.847444559382711e-05\n",
            "Epoch 841 Loss: 4.837608055752033e-05\n",
            "Epoch 842 Loss: 4.82790532537881e-05\n",
            "Epoch 843 Loss: 4.818235448960655e-05\n",
            "Epoch 844 Loss: 4.808489045327908e-05\n",
            "Epoch 845 Loss: 4.7989881472452075e-05\n",
            "Epoch 846 Loss: 4.789570065820131e-05\n",
            "Epoch 847 Loss: 4.7802381961715275e-05\n",
            "Epoch 848 Loss: 4.770945957767046e-05\n",
            "Epoch 849 Loss: 4.7617790348990886e-05\n",
            "Epoch 850 Loss: 4.75245456764851e-05\n",
            "Epoch 851 Loss: 4.7433592730557776e-05\n",
            "Epoch 852 Loss: 4.734272753690758e-05\n",
            "Epoch 853 Loss: 4.725555974461219e-05\n",
            "Epoch 854 Loss: 4.716644425803499e-05\n",
            "Epoch 855 Loss: 4.7078957698578934e-05\n",
            "Epoch 856 Loss: 4.699211933306323e-05\n",
            "Epoch 857 Loss: 4.690501311103238e-05\n",
            "Epoch 858 Loss: 4.681953422259752e-05\n",
            "Epoch 859 Loss: 4.673570511547082e-05\n",
            "Epoch 860 Loss: 4.6651388596980425e-05\n",
            "Epoch 861 Loss: 4.656697496765904e-05\n",
            "Epoch 862 Loss: 4.648401537118884e-05\n",
            "Epoch 863 Loss: 4.6401716056792506e-05\n",
            "Epoch 864 Loss: 4.631956341128381e-05\n",
            "Epoch 865 Loss: 4.6238477962093555e-05\n",
            "Epoch 866 Loss: 4.6158539802147894e-05\n",
            "Epoch 867 Loss: 4.607962663692966e-05\n",
            "Epoch 868 Loss: 4.600072059808393e-05\n",
            "Epoch 869 Loss: 4.591957193732919e-05\n",
            "Epoch 870 Loss: 4.5841016657591095e-05\n",
            "Epoch 871 Loss: 4.5762716201866185e-05\n",
            "Epoch 872 Loss: 4.568250587222235e-05\n",
            "Epoch 873 Loss: 4.560681291746648e-05\n",
            "Epoch 874 Loss: 4.55306171359083e-05\n",
            "Epoch 875 Loss: 4.545479223416138e-05\n",
            "Epoch 876 Loss: 4.537937663706013e-05\n",
            "Epoch 877 Loss: 4.530480679751724e-05\n",
            "Epoch 878 Loss: 4.522925345024285e-05\n",
            "Epoch 879 Loss: 4.515509630616113e-05\n",
            "Epoch 880 Loss: 4.50795827975201e-05\n",
            "Epoch 881 Loss: 4.5006107264255775e-05\n",
            "Epoch 882 Loss: 4.493172014809529e-05\n",
            "Epoch 883 Loss: 4.48583827941556e-05\n",
            "Epoch 884 Loss: 4.4786126050281643e-05\n",
            "Epoch 885 Loss: 4.471439015990122e-05\n",
            "Epoch 886 Loss: 4.464027844307256e-05\n",
            "Epoch 887 Loss: 4.456593259784949e-05\n",
            "Epoch 888 Loss: 4.449188340412502e-05\n",
            "Epoch 889 Loss: 4.442025654963278e-05\n",
            "Epoch 890 Loss: 4.434610146444258e-05\n",
            "Epoch 891 Loss: 4.427137700272227e-05\n",
            "Epoch 892 Loss: 4.4200663631513576e-05\n",
            "Epoch 893 Loss: 4.4125478282054446e-05\n",
            "Epoch 894 Loss: 4.4052686320494615e-05\n",
            "Epoch 895 Loss: 4.397782037769143e-05\n",
            "Epoch 896 Loss: 4.3904600053115444e-05\n",
            "Epoch 897 Loss: 4.3830316573618325e-05\n",
            "Epoch 898 Loss: 4.3755191119230654e-05\n",
            "Epoch 899 Loss: 4.3680407781439456e-05\n",
            "Epoch 900 Loss: 4.360521479155669e-05\n",
            "Epoch 901 Loss: 4.353022563047049e-05\n",
            "Epoch 902 Loss: 4.345526874774082e-05\n",
            "Epoch 903 Loss: 4.338057190898435e-05\n",
            "Epoch 904 Loss: 4.3305433369605284e-05\n",
            "Epoch 905 Loss: 4.323050577276598e-05\n",
            "Epoch 906 Loss: 4.315594662594893e-05\n",
            "Epoch 907 Loss: 4.3082030020156376e-05\n",
            "Epoch 908 Loss: 4.300598796602446e-05\n",
            "Epoch 909 Loss: 4.293068258947848e-05\n",
            "Epoch 910 Loss: 4.2857047368155425e-05\n",
            "Epoch 911 Loss: 4.278128508731044e-05\n",
            "Epoch 912 Loss: 4.270629565307084e-05\n",
            "Epoch 913 Loss: 4.2633660913594154e-05\n",
            "Epoch 914 Loss: 4.256093826716158e-05\n",
            "Epoch 915 Loss: 4.2487922356783705e-05\n",
            "Epoch 916 Loss: 4.2413970937491474e-05\n",
            "Epoch 917 Loss: 4.2339724426094696e-05\n",
            "Epoch 918 Loss: 4.226894914287518e-05\n",
            "Epoch 919 Loss: 4.219922668708204e-05\n",
            "Epoch 920 Loss: 4.212776567448611e-05\n",
            "Epoch 921 Loss: 4.205872734635279e-05\n",
            "Epoch 922 Loss: 4.199180549731771e-05\n",
            "Epoch 923 Loss: 4.192465400887824e-05\n",
            "Epoch 924 Loss: 4.1855201230242354e-05\n",
            "Epoch 925 Loss: 4.179132196316975e-05\n",
            "Epoch 926 Loss: 4.172853007400484e-05\n",
            "Epoch 927 Loss: 4.166641970394477e-05\n",
            "Epoch 928 Loss: 4.160367689064139e-05\n",
            "Epoch 929 Loss: 4.1545246695992826e-05\n",
            "Epoch 930 Loss: 4.1486524725678085e-05\n",
            "Epoch 931 Loss: 4.1430805383774694e-05\n",
            "Epoch 932 Loss: 4.137528509523492e-05\n",
            "Epoch 933 Loss: 4.132216462054202e-05\n",
            "Epoch 934 Loss: 4.12699356859819e-05\n",
            "Epoch 935 Loss: 4.122186990739754e-05\n",
            "Epoch 936 Loss: 4.1174983977665545e-05\n",
            "Epoch 937 Loss: 4.1131107292115476e-05\n",
            "Epoch 938 Loss: 4.108628161638406e-05\n",
            "Epoch 939 Loss: 4.104363208914309e-05\n",
            "Epoch 940 Loss: 4.1005886757680887e-05\n",
            "Epoch 941 Loss: 4.0969018592784214e-05\n",
            "Epoch 942 Loss: 4.093273954159589e-05\n",
            "Epoch 943 Loss: 4.0897891843540856e-05\n",
            "Epoch 944 Loss: 4.086722458500175e-05\n",
            "Epoch 945 Loss: 4.0836646596354184e-05\n",
            "Epoch 946 Loss: 4.080908270797815e-05\n",
            "Epoch 947 Loss: 4.078207692721222e-05\n",
            "Epoch 948 Loss: 4.0757602097777136e-05\n",
            "Epoch 949 Loss: 4.073498513330014e-05\n",
            "Epoch 950 Loss: 4.071370029024349e-05\n",
            "Epoch 951 Loss: 4.0695808371968196e-05\n",
            "Epoch 952 Loss: 4.06789775736392e-05\n",
            "Epoch 953 Loss: 4.066336718064387e-05\n",
            "Epoch 954 Loss: 4.064687525720439e-05\n",
            "Epoch 955 Loss: 4.0632808915208925e-05\n",
            "Epoch 956 Loss: 4.062066604709193e-05\n",
            "Epoch 957 Loss: 4.0604949002425634e-05\n",
            "Epoch 958 Loss: 4.059223593141204e-05\n",
            "Epoch 959 Loss: 4.05759498323555e-05\n",
            "Epoch 960 Loss: 4.056135735732735e-05\n",
            "Epoch 961 Loss: 4.054628589459174e-05\n",
            "Epoch 962 Loss: 4.053056981397613e-05\n",
            "Epoch 963 Loss: 4.05128075906849e-05\n",
            "Epoch 964 Loss: 4.049275777414807e-05\n",
            "Epoch 965 Loss: 4.0469033291717515e-05\n",
            "Epoch 966 Loss: 4.044448897060659e-05\n",
            "Epoch 967 Loss: 4.041467373670228e-05\n",
            "Epoch 968 Loss: 4.037945793605547e-05\n",
            "Epoch 969 Loss: 4.034102202502788e-05\n",
            "Epoch 970 Loss: 4.0298389857085734e-05\n",
            "Epoch 971 Loss: 4.024976625589769e-05\n",
            "Epoch 972 Loss: 4.019372018156772e-05\n",
            "Epoch 973 Loss: 4.0130971331289066e-05\n",
            "Epoch 974 Loss: 4.006048542672158e-05\n",
            "Epoch 975 Loss: 3.9984244624646395e-05\n",
            "Epoch 976 Loss: 3.99011883330308e-05\n",
            "Epoch 977 Loss: 3.98058797534935e-05\n",
            "Epoch 978 Loss: 3.970217022868945e-05\n",
            "Epoch 979 Loss: 3.958718013109677e-05\n",
            "Epoch 980 Loss: 3.9464357065619626e-05\n",
            "Epoch 981 Loss: 3.933009285081543e-05\n",
            "Epoch 982 Loss: 3.9189358485914904e-05\n",
            "Epoch 983 Loss: 3.904058960492481e-05\n",
            "Epoch 984 Loss: 3.8879649141631255e-05\n",
            "Epoch 985 Loss: 3.871116649758019e-05\n",
            "Epoch 986 Loss: 3.853499657930744e-05\n",
            "Epoch 987 Loss: 3.8351403455444644e-05\n",
            "Epoch 988 Loss: 3.815961518226608e-05\n",
            "Epoch 989 Loss: 3.796291712823202e-05\n",
            "Epoch 990 Loss: 3.776105987726543e-05\n",
            "Epoch 991 Loss: 3.7554573509738994e-05\n",
            "Epoch 992 Loss: 3.734470640641625e-05\n",
            "Epoch 993 Loss: 3.713485280554253e-05\n",
            "Epoch 994 Loss: 3.692226924380299e-05\n",
            "Epoch 995 Loss: 3.670893942913455e-05\n",
            "Epoch 996 Loss: 3.649775329209742e-05\n",
            "Epoch 997 Loss: 3.6290584340353746e-05\n",
            "Epoch 998 Loss: 3.608809011271768e-05\n",
            "Epoch 999 Loss: 3.5889894440101e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = outputs_norm_test * outputs.std() + outputs.mean()\n",
        "print(test_data)\n",
        "test_data_disp = test_data.to_numpy()[:,0]\n",
        "test_data_kappa = test_data.to_numpy()[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYI343W_kiCS",
        "outputId": "bd4e93e6-c0e7-481d-9ae0-fa1b68320c27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Displacement u [m]  Curvature kappa [m-1]\n",
            "993       -1.373861e-05           4.245900e-07\n",
            "859       -2.800103e-05           4.442457e-06\n",
            "298       -1.490108e-05           3.009846e-07\n",
            "553       -2.047168e-08          -8.608962e-06\n",
            "672       -3.259385e-05           4.974724e-06\n",
            "..                  ...                    ...\n",
            "167       -1.988783e-06          -4.455945e-06\n",
            "998       -1.846749e-05           2.057044e-06\n",
            "984       -1.218423e-05           9.053289e-07\n",
            "491       -4.836229e-06          -1.128942e-06\n",
            "10        -1.401570e-05          -1.128858e-06\n",
            "\n",
            "[300 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data_norm = model.predict(inputs_norm_test)\n",
        "pred_data_norm_df = pd.DataFrame(pred_data_norm, columns = ['Displacement u [m]','Curvature kappa [m-1]'])\n",
        "pred_data_df = pred_data_norm_df * outputs.std() + outputs.mean()\n",
        "print(pred_data_df)\n",
        "pred_data_disp = pred_data_df.to_numpy()[:,0]\n",
        "pred_data_kappa = pred_data_df.to_numpy()[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD3OdSkxkk0c",
        "outputId": "0b17f161-7b24-464c-85de-ce2104bd567f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "     Displacement u [m]  Curvature kappa [m-1]\n",
            "0         -1.382357e-05           4.477083e-07\n",
            "1         -2.800834e-05           4.462159e-06\n",
            "2         -1.500037e-05           3.280007e-07\n",
            "3          2.409384e-07          -8.613615e-06\n",
            "4         -3.254322e-05           4.972873e-06\n",
            "..                  ...                    ...\n",
            "295       -2.031039e-06          -4.399176e-06\n",
            "296       -1.844358e-05           2.036530e-06\n",
            "297       -1.217507e-05           8.896098e-07\n",
            "298       -4.906037e-06          -1.092847e-06\n",
            "299       -1.412885e-05          -1.058265e-06\n",
            "\n",
            "[300 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the mdoel on the test data and compare the error between predictions and true data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(test_data_disp, pred_data_disp, 'o')\n",
        "plt.show()\n",
        "plt.plot(test_data_kappa, pred_data_kappa, '*')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "yLIQgWNKkqm7",
        "outputId": "cda491b0-7ed9-4482-f852-0b67a1caae87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def F_model(x_norm,q_norm):\n",
        "    x_norm = tf.Variable(x_norm)\n",
        "    q_norm = tf.Variable(q_norm)\n",
        "    with tf.GradientTape() as g:\n",
        "      g.watch(x_norm)\n",
        "      with tf.GradientTape() as gg:\n",
        "        gg.watch(x_norm)\n",
        "        u_norm = model(tf.stack([x_norm,q_norm], axis=1))[:,0]\n",
        "      du_norm_dx_norm = gg.gradient(u_norm, x_norm)  \n",
        "    d2u_norm_dx_norm2 = g.gradient(du_norm_dx_norm, x_norm)  \n",
        "\n",
        "    # Chain rule\n",
        "    du_du_norm = outputs.std()[0]\n",
        "    dx_norm_dx = 1/inputs.std()[0]\n",
        "    d2u_dx2 =  du_du_norm *  d2u_norm_dx_norm2 * dx_norm_dx**2\n",
        "\n",
        "    u = u_norm * outputs.std()[0] + outputs.mean()[0]\n",
        "\n",
        "    return u, d2u_dx2"
      ],
      "metadata": {
        "id": "zt0LpU9jkvjV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_norm = inputs_norm_test.to_numpy()[:,0]\n",
        "q_norm = inputs_norm_test.to_numpy()[:,1]\n",
        "[u, d2u_dx2] = F_model(x_norm, q_norm)\n",
        "# print(d2u_dx2)\n",
        "plt.plot(d2u_dx2, test_data_kappa, '*')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "eQ36ISUek0a9",
        "outputId": "614dec45-72eb-4678-d7c7-2019704c3040"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}